<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 詹锟 | Kun Zhan </title> <meta name="author" content="Kun Zhan"> <meta name="description" content="Kun Zhan's personal website. Autonomous driving expert, AI researcher, and cognitive intelligence lead at Li Auto. "> <meta name="keywords" content="autonomous driving, computer vision, 3D vision, large language models, world models, AI, machine learning, robotics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%97&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhankunliauto.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> 詹锟 | Kun Zhan </h1> <p class="desc">Cognitive Intelligence Lead at <a href="https://www.lixiang.com/" rel="external nofollow noopener" target="_blank">Li Auto</a> | Autonomous Driving Expert | AI Researcher</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?974957d202f671e4fa6700c04e68deae" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>📧 zk_1028@aliyun.com</p> <p>📱 15210600944</p> <p>Beijing, China</p> </div> </div> <div class="clearfix"> <h1 id="詹锟-kun-zhan-">詹锟 (Kun Zhan) 👋</h1> <h2 id="-自动驾驶算法专家--ai-researcher">🚀 自动驾驶算法专家 | AI Researcher</h2> <p><a href="https://scholar.google.com/citations?user=1J061HIAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/Google%20Scholar-4285F4?style=flat&amp;logo=google-scholar&amp;logoColor=white" alt="Google Scholar"></a> <a href="mailto:zk_1028@aliyun.com"><img src="https://img.shields.io/badge/Email-zk__1028%40aliyun.com-D14836?style=flat&amp;logo=gmail&amp;logoColor=white" alt="Email"></a> <a href=""><img src="https://img.shields.io/badge/Phone-15210600944-25D366?style=flat&amp;logo=whatsapp&amp;logoColor=white" alt="Phone"></a></p> <h2 id="-关于我--about-me">🔭 关于我 | About Me</h2> <p>你好，我是詹锟（Kun Zhan）。目前在理想汽车担任认知智能负责人，带领团队专注于认知模型、世界模型和强化学习等方向的研发与落地。</p> <p>我的研究”野心”很大：自动驾驶、计算机视觉、3D视觉、大语言模型、具身智能… 基本上只要能让车子”更聪明”的技术，我都想研究个遍！特别痴迷于把最前沿的AI技术实实在在地装进机器人/车里，让科幻电影里的场景变成现实，实现无人化的未来。</p> <p>对我而言，技术创新不仅是理论突破，更应该是能够切实改变人们出行方式的实践。希望能通过不断探索，为自动驾驶技术的发展贡献自己的力量。</p> <h2 id="-研究领域--research-interests">🌟 研究领域 | Research Interests</h2> <ul> <li> <strong>自动驾驶 (Autonomous Driving)</strong>: 端到端自动驾驶系统、决策规划</li> <li> <strong>计算机视觉 (Computer Vision)</strong>: 目标检测与跟踪、场景理解</li> <li> <strong>3D视觉 (3D Vision)</strong>: 3D感知、重建与建模</li> <li> <strong>大模型应用 (Large Language Models)</strong>: 多模态大模型在自动驾驶中的应用</li> <li> <strong>世界模型 (World Models)</strong>: 环境建模与预测、强化学习</li> </ul> <h2 id="-工作经历--work-experience">💼 工作经历 | Work Experience</h2> <h3 id="理想汽车-li-auto--20214---至今">理想汽车 (Li Auto) | 2021.4 - 至今</h3> <p>认知智能负责人，带领团队研发前沿自动驾驶技术，专注于认知模型、世界模型和强化学习等方向的研发与落地。</p> <h3 id="百度-baidu--20164---20213">百度 (Baidu) | 2016.4 - 2021.3</h3> <p>自动驾驶研究员，参与开发计算机视觉和人工智能解决方案，用于自动驾驶车辆。</p> <h2 id="-学术成果--academic-achievements">📚 学术成果 | Academic Achievements</h2> <h3 id="引用统计--citations">引用统计 | Citations</h3> <ul> <li>总引用: 286+</li> <li>h-index: 7</li> <li>i10-index: 6</li> </ul> <h3 id="代表性论文--selected-publications">代表性论文 | Selected Publications</h3> <ol> <li> <p><strong>Drivevlm: The convergence of autonomous driving and large vision-language models</strong> (2024)<br> X Tian, J Gu, B Li, Y Liu, Y Wang, Z Zhao, <strong>K Zhan</strong>, P Jia, X Lang, H Zhao<br> <em>arXiv preprint arXiv:2402.12289</em> | 引用: 107</p> </li> <li> <p><strong>Street gaussians: Modeling dynamic urban scenes with gaussian splatting</strong> (2024)<br> Y Yan, H Lin, C Zhou, W Wang, H Sun, <strong>K Zhan</strong>, X Lang, X Zhou, S Peng<br> <em>European Conference on Computer Vision, 156-173</em> | 引用: 102</p> </li> <li> <p><strong>Planagent: A multi-modal large language agent for closed-loop vehicle motion planning</strong> (2024)<br> Y Zheng, Z Xing, Q Zhang, B Jin, P Li, Y Zheng, Z Xia, <strong>K Zhan</strong>, X Lang, D Zhao<br> <em>arXiv preprint arXiv:2406.01587</em> | 引用: 12</p> </li> <li> <p><strong>Tod3cap: Towards 3d dense captioning in outdoor scenes</strong> (2024)<br> B Jin, Y Zheng, P Li, W Li, Y Zheng, S Hu, X Liu, J Zhu, Z Yan, H Sun, <strong>K Zhan</strong>, X Lang, P Jia<br> <em>European Conference on Computer Vision, 367-384</em> | 引用: 10</p> </li> <li> <p><strong>Unleashing generalization of end-to-end autonomous driving with controllable long video generation</strong> (2024)<br> E Ma, L Zhou, T Tang, Z Zhang, D Han, J Jiang, <strong>K Zhan</strong>, P Jia, X Lang, K Yu<br> <em>arXiv preprint arXiv:2406.01349</em> | 引用: 9</p> </li> </ol> <h3 id="专利--patents">专利 | Patents</h3> <ul> <li>申请中美专利八项</li> </ul> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 05, 2024</th> <td> New preprint: “PlanAgent: A Multi-modal Large Language Agent for Closed-loop Vehicle Motion Planning” is now available on arXiv. This work introduces a novel approach for autonomous vehicle planning using large language models. </td> </tr> <tr> <th scope="row" style="width: 20%">May 15, 2024</th> <td> <a class="news-title" href="/news/announcement_2/">Street Gaussians accepted to ECCV 2024</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 10, 2024</th> <td> Our paper “TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes” has been accepted to ECCV 2024! This work enhances scene understanding for autonomous systems through detailed 3D captioning. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 20, 2024</th> <td> Our paper “DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models” is now available on arXiv! This work integrates LVLMs with autonomous driving systems for more intuitive human-vehicle interaction. </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Dec 04, 2024</th> <td> <a class="news-title" href="/blog/2024/photo-gallery/">a post with image galleries</a> </td> </tr> <tr> <th scope="row" style="width: 20%">May 14, 2024</th> <td> <a class="news-title" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> <a class="news-title" href="/blog/2024/tabs/">a post with tabs</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://journals.aps.org/" rel="external nofollow noopener" target="_blank">PhysRev</a> </abbr> </div> <div id="PhysRev.47.777" class="col-sm-8"> <div class="title">Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?</div> <div class="author"> <em>A. Einstein<sup>*†</sup></em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" rel="external nofollow noopener" target="_blank">B. Podolsky<sup>*</sup></a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" rel="external nofollow noopener" target="_blank">N. Rosen<sup>*</sup></a> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Example use of superscripts&lt;br&gt;† Albert Einstein"> </i> </div> <div class="periodical"> <em>Phys. Rev.</em>, New Jersey. <em>More Information</em> can be <a href="https://github.com/alshedivat/al-folio/" rel="external nofollow noopener" target="_blank">found here</a> , May 1935 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1103/PhysRev.47.777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-altmetric-id="248277"></span> <span class="__dimensions_badge_embed__" data-doi="10.1103/PhysRev.47.777" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=1J061HIAAAAJ&amp;citation_for_view=1J061HIAAAAJ:qyhmnyLat1gC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> <a href="https://inspirehep.net/literature/3255" aria-label="Inspirehep link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/inspire-4.2K-001628?logo=inspire&amp;logoColor=001628&amp;labelColor=beige" alt="4.2K InspireHEP citations"> </a> </div> <div class="abstract hidden"> <p>In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/drivevlm-480.webp 480w,/assets/img/publication_preview/drivevlm-800.webp 800w,/assets/img/publication_preview/drivevlm-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/drivevlm.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="drivevlm.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tian2024drivevlm" class="col-sm-8"> <div class="title">Drivevlm: The convergence of autonomous driving and large vision-language models</div> <div class="author"> Xiaoyu Tian, Jianfeng Gu, Bingqian Li, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Yiyang Liu, Yuhang Wang, Zhenyu Zhao, Kun Zhan, Ping Jia, Xiaoxue Lang, Hang Zhao' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2402.12289</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2402.12289" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper introduces DriveVLM, a novel approach that integrates large vision-language models (LVLMs) with autonomous driving systems. DriveVLM enables natural language interaction with autonomous vehicles, allowing for intuitive communication about driving scenarios, decision-making processes, and environmental perception. The system combines the reasoning capabilities of LVLMs with specialized driving knowledge, creating a more transparent and user-friendly autonomous driving experience.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/street_gaussians-480.webp 480w,/assets/img/publication_preview/street_gaussians-800.webp 800w,/assets/img/publication_preview/street_gaussians-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/street_gaussians.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="street_gaussians.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yan2024street" class="col-sm-8"> <div class="title">Street gaussians: Modeling dynamic urban scenes with gaussian splatting</div> <div class="author"> Yuanxing Yan, Hao Lin, Cheng Zhou, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Wenshan Wang, Hang Sun, Kun Zhan, Xiaoxue Lang, Xiwu Zhou, Shuaicheng Peng' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2401.01339" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Street Gaussians presents a novel approach for modeling dynamic urban scenes using 3D Gaussian Splatting. This method effectively captures both static and dynamic elements in complex urban environments, providing high-quality, real-time rendering capabilities. The approach addresses challenges in representing moving objects, varying lighting conditions, and complex geometries, making it particularly valuable for autonomous driving simulation and training.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/planagent-480.webp 480w,/assets/img/publication_preview/planagent-800.webp 800w,/assets/img/publication_preview/planagent-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/planagent.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="planagent.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zheng2024planagent" class="col-sm-8"> <div class="title">Planagent: A multi-modal large language agent for closed-loop vehicle motion planning</div> <div class="author"> Yiran Zheng, Zhengyuan Xing, Qingwen Zhang, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Boyi Jin, Pengfei Li, Yifan Zheng, Zhengyu Xia, Kun Zhan, Xiaoxue Lang, Dongbin Zhao' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.01587</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2406.01587" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>PlanAgent introduces a multi-modal large language agent framework for closed-loop vehicle motion planning. This innovative approach leverages large language models to interpret complex driving scenarios, reason about traffic rules and safety constraints, and generate appropriate motion plans. The agent integrates visual perception, natural language reasoning, and specialized driving knowledge to create a more interpretable and adaptable planning system for autonomous vehicles.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tod3cap-480.webp 480w,/assets/img/publication_preview/tod3cap-800.webp 800w,/assets/img/publication_preview/tod3cap-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/tod3cap.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tod3cap.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="jin2024tod3cap" class="col-sm-8"> <div class="title">Tod3cap: Towards 3d dense captioning in outdoor scenes</div> <div class="author"> Boyi Jin, Yiran Zheng, Pengfei Li, and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Wenhai Li, Yifan Zheng, Shuai Hu, Xingyu Liu, Jingdong Zhu, Zhengyu Yan, Hang Sun, Kun Zhan, Xiaoxue Lang, Ping Jia' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">10 more authors</span> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2403.09427" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>TOD3Cap presents a novel approach for 3D dense captioning in outdoor scenes, particularly focusing on autonomous driving environments. This method generates detailed textual descriptions of objects and regions within 3D space, enhancing scene understanding for autonomous systems. The approach combines advanced 3D perception with natural language generation, creating a more comprehensive representation of the driving environment that can be used for improved decision-making and human-vehicle interaction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/video_generation-480.webp 480w,/assets/img/publication_preview/video_generation-800.webp 800w,/assets/img/publication_preview/video_generation-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/video_generation.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="video_generation.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2024unleashing" class="col-sm-8"> <div class="title">Unleashing generalization of end-to-end autonomous driving with controllable long video generation</div> <div class="author"> Erkang Ma, Lina Zhou, Tianyu Tang, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Zhiyu Zhang, Dong Han, Jiangtao Jiang, Kun Zhan, Ping Jia, Xiaoxue Lang, Kai Yu' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.01349</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2406.01349" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This research introduces a novel approach for enhancing end-to-end autonomous driving systems through controllable long video generation. The method addresses the generalization challenges in autonomous driving by generating diverse, realistic driving scenarios for training and evaluation. By leveraging advanced video generation techniques with specific control mechanisms, the system can create extended driving sequences that maintain temporal consistency while representing a wide range of driving conditions and edge cases.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%7A%6B_%31%30%32%38@%61%6C%69%79%75%6E.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> <a href="https://scholar.google.com/citations?user=1J061HIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://wa.me/15210600944" title="whatsapp" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-whatsapp"></i></a> <a href="https://www.alberteinstein.com/" title="Custom Social" rel="external nofollow noopener" target="_blank"> <img src="https://www.alberteinstein.com/wp-content/uploads/2024/03/cropped-favicon-192x192.png" alt="Custom Social"> </a> </div> <div class="contact-note">Feel free to reach out via email or phone for collaborations, research discussions, or opportunities. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kun Zhan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>